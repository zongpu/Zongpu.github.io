<!DOCTYPE html>
<html lang="en">
  <head><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="description" content="AndrewNg Machine Learning 总结之Linear regression"/><meta name="keywords" content="Linear regression, Matlab, ZongPu'Blog" /><link rel="alternate" href="/default" title="ZongPu'Blog"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.11.0" />
<link rel="canonical" href="http://yoursite.com/2020/01/09/AndrewNgMachineLearning总结之LinearRegression/"/>

<link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css" />
<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.11.0" />

<script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>
<script>
  window.config = {"leancloud":{"app_id":null,"app_key":null},"toc":true,"fancybox":true,"pjax":"","latex":false};
</script>

    <title>AndrewNg Machine Learning 总结之Linear regression - ZongPu'Blog</title>
  <meta name="generator" content="Hexo 4.2.0"></head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">ZongPu'Blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list"><a href="/">
        <li class="mobile-menu-item">Home
          </li>
      </a></ul>
</nav>
<div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">ZongPu'Blog</a>
</div>

<nav class="site-navbar"><ul id="menu" class="menu"><li class="menu-item">
          <a class="menu-item-link" href="/">
            Home
            </a>
        </li>
      </ul></nav>
</header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content"><article class="post">
    <header class="post-header">
      <h1 class="post-title">AndrewNg Machine Learning 总结之Linear regression
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2020-01-09
        </span><span class="post-category">
            <a href="/categories/Machine-Learning/">Machine Learning</a>
            </span>
        </div>
    </header>

    <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">Contents</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Linear-regression"><span class="toc-text">Linear regression</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#线性回归模型："><span class="toc-text">线性回归模型：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#代价函数："><span class="toc-text">代价函数：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#梯度下降法更新theta："><span class="toc-text">梯度下降法更新theta：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#正规方程法直接得到theta解析解："><span class="toc-text">正规方程法直接得到theta解析解：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#特征归一化："><span class="toc-text">特征归一化：</span></a></li></ol></li></ol>
    </div>
  </div><div class="post-content"><h1 id="Linear-regression"><a href="#Linear-regression" class="headerlink" title="Linear regression"></a>Linear regression</h1><h2 id="线性回归模型："><a href="#线性回归模型：" class="headerlink" title="线性回归模型："></a>线性回归模型：</h2><p>$$<br>h_\theta(x)=\theta^Tx<br>$$</p>
<h2 id="代价函数："><a href="#代价函数：" class="headerlink" title="代价函数："></a>代价函数：</h2><p>$$<br>J(\theta)={(1/2m)}{\sum_{i=1}^{m}{(h_\theta(x^{(i)})-y^{(i)})^2}}<br>$$</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">J</span> = <span class="title">computeCost</span><span class="params">(X, y, theta)</span></span></span><br><span class="line">m = <span class="built_in">length</span>(y);<span class="comment">% number of training examples</span></span><br><span class="line">方法<span class="number">1</span>：</span><br><span class="line"> <span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:m</span><br><span class="line">     J=J+(X(<span class="built_in">i</span>,:)*theta-y(<span class="built_in">i</span>,:))^<span class="number">2</span>/(<span class="number">2</span>*m);</span><br><span class="line"> <span class="keyword">end</span></span><br><span class="line">方法<span class="number">2</span>：</span><br><span class="line">J=sum((X*theta-y).^<span class="number">2</span>)/(<span class="number">2</span>*m);<span class="comment">%此处用.^2对每个值求平方,然后用sum()函数求和利用sunm()函数</span></span><br><span class="line"></span><br><span class="line">方法<span class="number">3</span>：（通用于单变量、多变量回归）</span><br><span class="line">J=((X*theta-y)'*(X*theta-y))/(<span class="number">2</span>*m);<span class="comment">%向量相乘亦可得到同样的和值</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>

<h2 id="梯度下降法更新theta："><a href="#梯度下降法更新theta：" class="headerlink" title="梯度下降法更新theta："></a>梯度下降法更新theta：</h2><p>$$<br>\theta_j:=\theta_j-\alpha(1/m){\sum_{i=1}^{m}{(h_\theta(x^{(i)})-y^{(i)}){x_j^{(i)}}}}<br>$$</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[theta, J_history]</span> = <span class="title">gradientDescent</span><span class="params">(X, y, theta, alpha, num_iters)</span></span></span><br><span class="line">m = <span class="built_in">length</span>(y); </span><br><span class="line">J_history = <span class="built_in">zeros</span>(num_iters, <span class="number">1</span>);</span><br><span class="line"><span class="keyword">for</span> iter = <span class="number">1</span>:num_iters</span><br><span class="line"><span class="comment">%     x=X(:,2);%得到列向量x1</span></span><br><span class="line"><span class="comment">%     theta0=theta(1);%得到初值，</span></span><br><span class="line"><span class="comment">%     theta1=theta(2);</span></span><br><span class="line"><span class="comment">%     theta0=theta0-(alpha/m)*sum((X*theta-y));%x0为全1的列向量，不必写出</span></span><br><span class="line"><span class="comment">%     theta1=theta1-(alpha/m)*sum((X*theta-y).*x);%使用点乘.*直接得到每组数据相乘结果</span></span><br><span class="line"><span class="comment">%     theta=[theta0;</span></span><br><span class="line"><span class="comment">%                theta1];%theta是size(2,1)的矩阵，定义时theta = zeros(2, 1)这里theta0与theta1之间应该用分号隔开，表示两行</span></span><br><span class="line">           </span><br><span class="line"> theta = theta - alpha / m * X' * (X * theta - y);<span class="comment">%整合上面对每个theta操作，写成矩阵形式</span></span><br><span class="line"> <span class="comment">%为了绘制出J(theta)曲线</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">% Save the cost J in every iteration    </span></span><br><span class="line">    J_history(iter) = computeCost(X, y, theta);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>

<h2 id="正规方程法直接得到theta解析解："><a href="#正规方程法直接得到theta解析解：" class="headerlink" title="正规方程法直接得到theta解析解："></a>正规方程法直接得到theta解析解：</h2><p>$$<br>\theta=(X^TX)^{-1}{X^T}y<br>$$</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[theta]</span> = <span class="title">normalEqn</span><span class="params">(X, y)</span></span></span><br><span class="line">theta = <span class="built_in">zeros</span>(<span class="built_in">size</span>(X, <span class="number">2</span>), <span class="number">1</span>);</span><br><span class="line"><span class="comment">% theta=((X'*X)^-1)*X'*y;</span></span><br><span class="line">theta = pinv(X' * X) * X' * y;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>

<h2 id="特征归一化："><a href="#特征归一化：" class="headerlink" title="特征归一化："></a>特征归一化：</h2><p>$$<br>x:=(x^i-mu)/s^i<br>$$</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[X_norm, mu, sigma]</span> = <span class="title">featureNormalize</span><span class="params">(X)</span></span></span><br><span class="line">X_norm = X;</span><br><span class="line">mu = <span class="built_in">zeros</span>(<span class="number">1</span>, <span class="built_in">size</span>(X, <span class="number">2</span>));</span><br><span class="line">sigma = <span class="built_in">zeros</span>(<span class="number">1</span>, <span class="built_in">size</span>(X, <span class="number">2</span>));    </span><br><span class="line">m = <span class="built_in">length</span>(X(:,<span class="number">1</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">%for i=1:size(X, 2)</span></span><br><span class="line"><span class="comment">%mu(i)=sum(X(:,i))/m;</span></span><br><span class="line"><span class="comment">%sigma(i)=std(X(:,i));%std(X(:,1)) computes the standard deviation</span></span><br><span class="line"><span class="comment">%x=(X(:,i)-mu(i))./sigma(i);%X(:,i)-mu(i))表示每列的每个元素减去均值，./表示点除</span></span><br><span class="line"><span class="comment">%X_norm(:,i)=x;</span></span><br><span class="line"><span class="comment">%end</span></span><br><span class="line"></span><br><span class="line"> mu=<span class="built_in">mean</span>(X);</span><br><span class="line"> sigma=std(X);</span><br><span class="line"> <span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:<span class="built_in">size</span>(X,<span class="number">2</span>),</span><br><span class="line">     X_norm(:,<span class="built_in">i</span>) = (X(:,<span class="built_in">i</span>) - mu(<span class="built_in">i</span>)) / sigma(<span class="built_in">i</span>);</span><br><span class="line"> <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>




      </div>
      <div class="post-copyright">
    <p class="copyright-item">
      <span>Author: </span>
      <a href="http://yoursite.com">zongpu</a>
    </p>
    <p class="copyright-item">
      <span>Link: </span>
      <a href="http://yoursite.com/2020/01/09/AndrewNgMachineLearning%E6%80%BB%E7%BB%93%E4%B9%8BLinearRegression/">http://yoursite.com/2020/01/09/AndrewNgMachineLearning%E6%80%BB%E7%BB%93%E4%B9%8BLinearRegression/</a>
    </p>
    <p class="copyright-item">
      <span>License: </span><a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>
    </p>
  </div>
      <footer class="post-footer">
        <div class="post-tags">
            <a href="/tags/Linear-regression/">Linear regression</a>
            <a href="/tags/Matlab/">Matlab</a>
            </div>
        
        <nav class="post-nav"><a class="prev" href="/2020/01/09/CUDA+cuDNN+TF-%E5%AE%89%E8%A3%85%E6%B5%81%E7%A8%8B%E5%92%8C%E7%BB%8F%E9%AA%8C%E6%95%99%E8%AE%AD/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">CUDA+cuDNN+TF 安装流程和经验教训</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    <a class="next" href="/2020/01/09/2019%EF%BC%8C%E5%BC%80%E5%A7%8B%E8%BA%BA%E5%B9%B3/">
        <span class="next-text nav-default">2019，开始躺平</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    </nav></footer>
    </article></div><div class="comments" id="comments"></div></div>
      </main>

      <footer id="footer" class="footer"><div class="social-links"><a href="mailto:your@email.com" class="iconfont icon-email" title="email"></a>
        <a href="https://github.com/ahonn" target="_blank" rel="noopener" class="iconfont icon-github" title="github"></a>
        <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    </div><div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even" target="_blank" rel="noopener">Even</a>
  </span>

  <span class="copyright-year">&copy;2015 - 2020<span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">zongpu</span>
  </span>
</div>
</footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div><script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/js/src/even.js?v=2.11.0"></script>
</body>
</html>
